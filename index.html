<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
   <title>Rameswar Panda</title>

  <meta name="author" content="Rameswar Panda">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rameswar Panda</name>
              </p>
              <p>I am a research staff member at <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                I received my Ph.D. from <a href="http://www.ucr.edu">UC Riverside</a> in 2018, under the supervision of <a href="http://vcg.engr.ucr.edu/amit">Prof. Amit K. Roy-Chowdhury</a>.
<!--                Previously, I obtained my M.S. from <a href="http://www.jaduniv.edu.in/">Jadavpur University</a> in 2013 supervised by <a href="https://sites.google.com/site/anandachowdhury/">Prof. Ananda S. Chowdhury</a>.-->
                During Ph.D., I was very fortunate to have interned at <a href="http://www.nec-labs.com/">NEC Labs</a>, <a href="https://research.adobe.com/">Adobe Research</a> and <a href="http://www.usa.siemens.com/en/about_us/research/home.htm">Siemens Research</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:rpanda@ibm.com">Email</a> &nbsp/&nbsp
                <a href="data/CV_Rameswar.pdf">CV</a> &nbsp/&nbsp
                <a href="https://scholar.google.co.in/citations?user=_ySuu6gAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/rameswar-panda-0067b2ab">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/myphoto_circle.png"><img style="width:90%;max-width:90%" alt="profile photo" src="images/myphoto_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research interests mainly lie in the areas of computer vision and machine learning.
                In particular, my current focus is on image and video understanding including efficient dynamic neural networks, representation learning and learning with limited supervision.
                During my Ph.D., I worked on video summarization, person re-identification, and multi-modal embedding.
              </p>
            </td>
          </tr>
        </tbody></table>


        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <ul>
<!--                  <li> <span style="color: red; "><strong>[Internship]</strong></span> We are looking for motivated PhD students to work in several exciting areas including: video understanding, multimodal learning, efficient AI, and learning with less labels!-->
<!--                  Please send me an <a href="mailto:rpanda@ibm.com">email</a> if you are interested in doing research internship at MIT-IBM Watson AI Lab in Cambridge, MA.<br>-->
                  <li> Two papers on Efficient Video Understanding accepted at <a href="https://iclr.cc/Conferences/2021">ICLR 2021</a>.<br>
                  <li> We are organizing a workshop on <a href="https://sites.google.com/view/cvpr2021-dnetcv/">Dynamic Neural Networks Meets Computer Vision (DNetCV)</a> at <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>.<br>
                  <li> We are organizing the 2nd workshop and challenges on <a href="http://cvpr21-nas.com/">Neural Architecture Search (NAS)</a> at <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>.<br>
                  <li> Paper on Analyzing Transferability in Neural Architecture Search accepted at <a href="https://aaai.org/Conferences/AAAI-21/">AAAI 2021</a>.<br>
                  <li> Paper on Learning What to Share for Efficient Deep Multi-Task Learning accepted at <a href="https://nips.cc/">NeurIPS 2020</a>.<br>
                  <li> Paper on Unsupervised Video Person Re-Identification accepted at <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE TCSVT, 2020</a>.<br>
<!--              <li> Paper on Adversarial Knowledge Transfer from Unlabeled Data accepted at <a href="https://2020.acmmm.org/">ACM MM 2020</a>.<br>-->
<!--              <li> Paper on Adaptive Frame Resolution for Efficient Action Recognition accepted at <a href="https://eccv2020.eu/">ECCV 2020</a>.<br>-->
<!--              <li> Paper on Fairness of Classifiers Across Skin Tones in Dermatology accepted at <a href="https://www.miccai2020.org/en/">MICCAI 2020</a>.<br>-->
<!--              <li> We are organizing the 2nd edition of our <a href="https://sites.google.com/view/multimodalvideo-v2/">Workshop on Multi-Modal Video Analysis</a> at <a href="https://eccv2020.eu/">ECCV 2020</a>.<br>-->
<!--              <li> Paper on Non-Adversarial Video Synthesis with Learned Priors accepted at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.<br>-->
<!--              <li> Paper on Hypothesis Transfer Learning for Person Re-ID accepted at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.<br>-->
<!--              <li> We are organizing a <a href="https://sites.google.com/view/cvpr20-nas/">Workshop on Neural Architecture Search (NAS)</a> at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.<br>-->
              </ul>
            </td>
          </tr>
        </tbody></table>

<!--        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>-->
<!--            <tr>-->
<!--            <td style="padding:20px;width:100%;vertical-align:middle">-->
<!--              <heading>Preprints</heading>-->
<!--            </td>-->
<!--          </tr>-->
<!--        </tbody></table>-->

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>

<!--          <div style="width: 100%; height: 20px; border-bottom: 1px solid black; text-align: center">-->
<!--            <span style="font-size: 20px; background-color: #F3F5F6; padding: 0 10px;">-->
<!--            2020 &lt;!&ndash;Padding is optional&ndash;&gt;-->
<!--            </span>-->
<!--            </div> <br>-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICLR_2021_AdaFuse.png" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICLR_2021_AdaFuse.pdf>
                <papertitle>AdaFuse: Adaptive Temporal Fusion Network for Efficient Action Recognition</papertitle>
              </a>
              <br>
              Yue Meng, <strong>Rameswar Panda</strong>, Chung-Ching Lin, Prasanna Sattigeri, Leonid Karlinsky, Kate Saenko, Aude Oliva, Rogerio Feris<br>
              <em> International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021 <br>
<!--                [<a href="https://cs-people.bu.edu/sunxm/AdaShare/project.html">Project Page</a>] [<a href="https://github.com/sunxm2357/AdaShare">Code</a>] [<a href="https://rpand002.github.io/data/NeurIPS_2020_Supp.pdf">Supplementary Material</a>]<br>-->
              <p> We introduce an adaptive temporal fusion network that dynamically fuses channels from current and past feature maps for strong temporal modelling in action recognition.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICLR_2021_VARED.png" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICLR_2021_VARED.pdf>
                <papertitle>VA-RED<sup>2</sup>: Video Adaptive Redundancy Reduction</papertitle>
              </a>
              <br>
              Bowen Pan, <strong>Rameswar Panda</strong>, Camilo Fosco, Chung-Ching Lin, Alex Andonian, Yue Meng, Kate Saenko, Aude Oliva, Rogerio Feris<br>
              <em> International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2021 <br>
<!--                [<a href="https://cs-people.bu.edu/sunxm/AdaShare/project.html">Project Page</a>] [<a href="https://github.com/sunxm2357/AdaShare">Code</a>] [<a href="https://rpand002.github.io/data/NeurIPS_2020_Supp.pdf">Supplementary Material</a>]<br>-->
              <p> We propose an input-dependent adaptive framework for efficient video recognition that automatically decides what feature maps to compute per input instance.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/AAAI_2021.png" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href=data/AAAI_2021.pdf>
                <papertitle>NASTransfer: Analyzing Architecture Transferability in Large Scale Neural Architecture Search</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Michele Merler, Mayoore Jaiswal, Hui Wu, Kandan Ramakrishnan, Ulrich Finkler,
                Chun-Fu Chen, Minsik Cho, Rogerio Feris, David Kung, Bishwaranjan Bhattacharjee <br>
              <em> AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2021 <br>
<!--                [<a href="https://cs-people.bu.edu/sunxm/AdaShare/project.html">Project Page</a>] [<a href="https://github.com/sunxm2357/AdaShare">Code</a>] [<a href="https://rpand002.github.io/data/NeurIPS_2020_Supp.pdf">Supplementary Material</a>]<br>-->
              <p> We analyze the architecture transferability of different NAS methods by performing a series of experiments on several large scale image benchmarks.</p>
            </td>
          </tr> </tbody></table>

         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/NeurIPS_2020.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/NeurIPS_2020.pdf>
                <papertitle>AdaShare: Learning What To Share For Efficient Deep Multi-Task Learning</papertitle>
              </a>
              <br>
              Ximeng Sun, <strong>Rameswar Panda</strong>, Rogerio Feris, Kate Saenko <br>
              <em> Neural Information Processing Systems (<strong>NeurIPS</strong>)</em>, 2020 <br>
                [<a href="https://cs-people.bu.edu/sunxm/AdaShare/project.html">Project Page</a>] [<a href="https://github.com/sunxm2357/AdaShare">Code</a>] [<a href="https://rpand002.github.io/data/NeurIPS_2020_Supp.pdf">Supplementary Material</a>]<br>
              <p>We propose a novel approach for adaptively determining the feature sharing pattern across multiple tasks (what layers to share across which tasks) in deep multi-task learning.</p>
            </td>
          </tr> </tbody></table>


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TCSVT_2020.png" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href=data/TCSVT_2020.pdf>
                <papertitle>Exploiting Global Camera Network Constraints for Unsupervised Video Person Re-identification</papertitle>
              </a>
              <br>
              Xueping Wang, <strong>Rameswar Panda</strong>, Min Liu, Yaonan Wang, Amit K. Roy-Chowdhury<br>
              <em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)</em>, 2020
              <p> We propose a consistent cross-view matching framework, in which global camera network constraints are exploited to address the problem of unsupervised video-based re-identification.</p>
            </td>
          </tr> </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MM_2020.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/MM_2020.pdf>
                <papertitle>Adversarial Knowledge Transfer from Unlabeled Data</papertitle>
              </a>
              <br>
              Akash Gupta*, <strong>Rameswar Panda*</strong>, Sujoy Paul, Jianming Zhang, Amit K. Roy-Chowdhury<br>
              <em>ACM Multimedia (<strong>MM</strong>)</em>, 2020 <br>
                [<a href="https://agupt013.github.io/akt.html">Project Page</a>] [<a href="https://github.com/agupt013/akt">Code</a>] <br>
                <p>We present a novel adversarial framework for transferring knowledge from internet-scale unlabeled data to improve the performance of a classifier on a given visual recognition task.</p>
            </td>
          </tr> </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ECCV_2020.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ECCV_2020.pdf>
                <papertitle>AR-Net: Adaptive Frame Resolution for Efficient Action Recognition</papertitle>
              </a>
              <br>
              Yue Meng, Chung-Ching Lin, <strong>Rameswar Panda</strong>, Prasanna Sattigeri, Leonid Karlinsky, Aude Oliva, Kate Saenko, Rogerio Feris              <br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2020 <br>
                [<a href="https://mengyuest.github.io/AR-Net/">Project Page</a>] [<a href="https://github.com/mengyuest/AR-Net">Code</a>] <br>
              <p>We propose an adaptive approach to select optimal resolution for each frame conditioned on the input for efficient action recognition in long untrimmed video.</p>
            </td>
          </tr>
           </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ECCV_2020_W.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ECCV_2020_W.pdf>
                <papertitle>Mitigating Dataset Imbalance via Joint Generation and Classification</papertitle>
              </a>
              <br>
              Aadarsh Sahoo, Ankit Singh, <strong>Rameswar Panda</strong>, Rogerio Feris, Abir Das<br>
              <em>ECCV Workshop on Imbalance Problems in Computer Vision (<strong>ECCV-W</strong>)</em>, 2020
              <p>We introduce a joint dataset repairment strategy by combining classifier with a GAN that makes up for the deficit of training examples from the minority class by producing additional examples.</p>
            </td>
          </tr>
           </tbody></table>

           <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MICCAI_2020.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/MICCAI_2020.pdf>
                <papertitle>Fairness of Classifiers Across Skin Tones in Dermatology</papertitle>
              </a>
              <br>
              Newton M. Kinyanjui, Timothy Odonga, Celia Cintas, Noel C. F. Codella, <strong>Rameswar Panda</strong>, Prasanna Sattigeri, Kush R. Varshney<br>
              <em>Medical Image Computing and Computer Assisted Interventions (<strong>MICCAI</strong>)</em>, 2020
              <p>We present an approach to estimate the consistency in performance of classifiers across populations with varying skin tones in skin disease benchmarks.</p>
            </td>
          </tr>
           </tbody></table>

           <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CVPR_2020_Video.jpg" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/CVPR_2020_Video.pdf>
                <papertitle>Non-Adversarial Video Synthesis with Learned Priors</papertitle>
              </a>
              <br>
              Abhishek Aich*, Akash Gupta*, <strong>Rameswar Panda</strong>, Rakib Hyder, Salman Asif, Amit K. Roy-Chowdhury<br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020 <br>
                [<a href="https://abhishekaich27.github.io/navsynth.html">Project Page</a>] [<a href="https://github.com/abhishekaich27/Navsynth">Code</a>] <br>
              <p>We introduce a novel non-adversarial framework for generating a wide range of diverse videos  from latent noise vectors without any any conditional input reference frame.</p>
            </td>
          </tr> </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CVPR_2020_ReID.jpg" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/CVPR_2020_ReID.pdf>
                <papertitle>Camera On-boarding for Person Re-identification using Hypothesis Transfer Learning</papertitle>
              </a>
              <br>
              Sk Miraj Ahmed*, Aske R. Lejbolle*, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2020
              <p>We propose an approach to swiftly on-board new camera(s) in an existing re-id network using only source models and limited labeled data, but without having access to source camera data.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CVPR_2020_W.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/CVPR_2020_W.pdf>
                <papertitle>Relationship Matters: Relation Guided Knowledge Transfer for Incremental Learning of Object Detectors</papertitle>
              </a>
              <br>
              Kandan Ramakrishnan, <strong>Rameswar Panda</strong>, Quanfu Fan, John Henning, Aude Oliva, Rogerio Feris<br>
              <em>CVPR Workshop on Continual Learning in Computer Vision (<strong>CVPR-W</strong>)</em>, 2020
              <p>We introduce a novel approach that focuses on object relations to effectively transfer knowledge for minimizing the effect of catastrophic forgetting in incremental learning of object detectors.</p>
            </td>
          </tr> </tbody></table>

<!--          <div style="width: 100%; height: 20px; border-bottom: 1px solid black; text-align: center">-->
<!--            <span style="font-size: 20px; background-color: #F3F5F6; padding: 0 10px;">-->
<!--            2019 &lt;!&ndash;Padding is optional&ndash;&gt;-->
<!--            </span>-->
<!--            </div> <br>-->


          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/PR_2019.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/PR_2019.pdf>
                <papertitle>Adaptation of Person Re-identification Models for On-boarding New Camera(s)</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Amran Bhuiyan, Vittorio Murino, Amit K. Roy-Chowdhury<br>
              <em>Pattern Recognition (<strong>PR</strong>)</em>, 2019
              <p>This paper extends our CVPR 2017 paper providing a new source-target selective adaptation strategy and rigorous experiments on more person re-id datasets.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TCSVT_2019.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/TCSVT_2019.pdf>
                <papertitle>Construction of Diverse Image Datasets from Web Collections with Limited Labeling</papertitle>
              </a>
              <br>
              Niluthpol C. Mithun, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)</em>, 2019
              <p>This paper extends our MM 2016 paper where we employ a joint visual-semantic space to simultaneously utilize both images and text from the web for dataset construction.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/NeurIPSW_2019.png" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href=data/NeurIPSW_2019.pdf>
                <papertitle>Estimating Skin Tone and Effects on Classification Performance in Dermatology Datasets</papertitle>
              </a>
              <br>
              Newton M. Kinyanjui, Timothy Odonga, Celia Cintas, Noel C. F. Codella, <strong>Rameswar Panda</strong>, Prasanna Sattigeri, Kush R. Varshney<br>
              <em>NeurIPS Fair Machine Learning for Health Workshop (<strong>NeurIPS-W</strong>)</em>, 2019
              <p>We present an approach to estimate skin tone in benchmark skin disease datasets, and investigate whether model performance is dependent on this measure</p>
            </td>
          </tr>
           </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ECCV_2018.png" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ECCV_2018.pdf>
                <papertitle>Contemplating Visual Emotions: Understanding and Overcoming Dataset Bias</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Jianming Zhang, Haoxiang Li, Joon-Young Lee, Xin Lu, Amit K. Roy-Chowdhury<br>
              <em>European Conference on Computer Vision (<strong>ECCV</strong>)</em>, 2018 <br>
                [<a href="https://rpand002.github.io/emotion.html">Project Page</a>] [<a href="https://rpand002.github.io/data/ECCV_2018_Supp.pdf">Supplementary Material</a>]<br>
              <p>We investigate different dataset biases and propose a curriculum guided webly supervised approach for learning a generalizable emotion recognition model.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MM_2018.png" width="160" height="100">
            </td>
            <td width="75%" valign="middle">
              <a href=data/MM_2018.pdf>
                <papertitle>Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval</papertitle>
              </a>
              <br>
              Niluthpol C. Mithun, <strong>Rameswar Panda</strong>, Evangelos E. Papalexakis, Amit K. Roy-Chowdhury<br>
              <em>ACM Multimedia (<strong>MM</strong>)</em>, 2018
              <p>This work exploits large scale web data for learning an effective multi-modal embedding without requiring large amount of human-crafted training data.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CVPR_2018.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/CVPR_2018.pdf>
                <papertitle>FFNet: Video Fast-Forwarding via Reinforcement Learning</papertitle>
              </a>
              <br>
              Shuyue Lan, <strong>Rameswar Panda</strong>, Qi Zhu, Amit K. Roy-Chowdhury<br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2018
              <p>We introduce an online framework for fast-forwarding a video while presenting its important and interesting content on the fly without processing or even obtaining the entire video.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICCV_2017.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICCV_2017.pdf>
                <papertitle>Weakly Supervised Summarization of Web Videos</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Abir Das, Ziyan Wu, Jan Ernst, Amit K. Roy-Chowdhury<br>
              <em>International Conference on Computer Vision (<strong>ICCV</strong>)</em>, 2017
              <p>We introduce a weakly supervised approach that requires only video-level annotations for summarizing long unconstrained web videos.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CVPR_2017_ReID.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/CVPR_2017_ReID.pdf>
                <papertitle>Unsupervised Adaptive Re-identification in Open World Dynamic Camera Networks</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda*</strong>, Amran Bhuiyan*, Vittorio Murino, Amit K. Roy-Chowdhury<br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2017
              <p>We propose an unsupervised adaptation scheme for re-identification models where a new camera may be temporarily inserted into an existing system to get additional information.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CVPR_2017_Summ.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/CVPR_2017_Summ.pdf>
                <papertitle>Collaborative Summarization of Topic-Related Videos</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2017
              <p>This paper presents a collaborative video summarization approach that exploits visual context from a set of topic-related videos to extract an informative summary of a given video.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TMM_2017.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/TMM_2017.pdf>
                <papertitle>Multi-View Surveillance Video Summarization via Joint Embedding and Sparse Optimization</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>IEEE Transactions on Multimedia (<strong>TMM</strong>)</em>, 2017
              <p>This paper extends our ICPR 2016 paper providing new theoretical insights with a joint optimization and experimenting on spatio-temporal features and datasets.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TIP_2017.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/TIP_2017.pdf>
                <papertitle>Diversity-aware Multi-Video Summarization</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Niluthpol C. Mithun, Amit K. Roy-Chowdhury<br>
              <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2017
              <p>This paper introduces a new generalized sparse optimization framework for summarizing multiple videos generated from a video search or from a multi-view camera network.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/TCYB_2017.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/TCYB_2017.pdf>
                <papertitle>Nystrom approximated temporally constrained multi-similarity spectral clustering approach for movie scene detection</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Sanjay K. Kuanar, Ananda S. Chowdhury<br>
              <em>IEEE Transactions on Cybernetics (<strong>TCYB</strong>)</em>, 2017
              <p>We present a fast solution for movie scene detection using Nystrom approximated multi-similarity spectral clustering with a temporal integrity constraint.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICASSP_2017.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICASSP_2017.pdf>
                <papertitle>Sparse Modeling for Topic-oriented Video Summarization</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>IEEE International Conference on Acoustics, Speech and Signal Processing (<strong>ICASSP</strong>)</em>, 2017
              <p>This paper presents a diversity-aware sparse optimization framework for summarizing topi-related videos generated from a video search.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CVIU_2016.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/CVIU_2016.pdf>
                <papertitle>Continuous Adaptation of Multi-Camera Person Identification Models through Sparse Non-redundant Representative Selection</papertitle>
              </a>
              <br>
              Abir Das, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>Computer Vision and Image Understanding (<strong>CVIU</strong>)</em>, 2016
              <p>We addressed the problem of online learning of identification systems where unlabeled data comes in small minibatches, with human in the loop.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICPR_2016.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICPR_2016.pdf>
                <papertitle>Video Summarization in a Multi-View Camera Network</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Abir Das, Amit K. Roy-Chowdhury<br>
              <em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2016
              <p>This paper presents a framework for summarizing multi-view videos by exploiting both intra- and inter-view content correlations in a joint embedding space.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICIP_2016.png" width="160">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICIP_2016.pdf>
                <papertitle>Embedded Sparse Coding for Summarizing Multi-View Videos</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Abir Das, Amit K. Roy-Chowdhury<br>
              <em>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</em>, 2016
              <p>This paper presents a stochastic multi-view frame embedding based on KL divergence to preserve correlations in multi-view learning.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/MM_2016.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/MM_2016.pdf>
                <papertitle>Generating Diverse Image Datasets with Limited Labeling</papertitle>
              </a>
              <br>
              Niluthpol C. Mithun, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>ACM Multimedia (<strong>MM</strong>)</em>, 2016
              <p>This paper presents a semi-supervised sparse coding framework which can be used to both create a dataset from scratch or enrich an existing dataset with diverse examples.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICIP_2015.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICIP_2015.pdf>
                <papertitle>Active Image Pair Selection for Continuous Person Re-identification</papertitle>
              </a>
              <br>
              Abir Das, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
              <em>IEEE International Conference on Image Processing (<strong>ICIP</strong>)</em>, 2015
              <p>We present a continuous learning re-id system with a human in the loop which not only provides image labels but also improves the learned model by providing attribute based explanations..</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICPR_2014.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICPR_2014.pdf>
                <papertitle>Scalable Video Summarization using Skeleton Graph and Random Walk</papertitle>
              </a>
              <br>
              <strong>Rameswar Panda</strong>, Sanjay K. Kuanar, Ananda S. Chowdhury<br>
              <em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2014
              <p>This paper presents a scalable video summarization framework for both the analysis of the input video as well as the generation of summaries according to user-specified length constraints.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/JVCI_2013.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/JVCI_2013.pdf>
                <papertitle>Video Key frame Extraction through Dynamic Delaunay Clustering with a Structural Constraint</papertitle>
              </a>
              <br>
              Sanjay K. Kuanar, <strong>Rameswar Panda</strong>, Ananda S. Chowdhury<br>
              <em>Journal of Visual Communication and Image Representation (<strong>JVCIR</strong>)</em>, 2013
              <p>This paper extends our ICPR 2012 paper providing new theoretical insights and experiments on more datasets including different key frame visualization techniques.</p>
            </td>
          </tr> </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr onmouseout="nlt_stop()" onmouseover="nlt_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/ICPR_2012.png" width="160" height="90">
            </td>
            <td width="75%" valign="middle">
              <a href=data/ICPR_2012.pdf>
                <papertitle>Video Storyboard Design using Delaunay Graphs</papertitle>
              </a>
              <br>
              Ananda S. Chowdhury, Sanjay K. Kuanar, <strong>Rameswar Panda</strong>, Moloy N. Das<br>
              <em>IEEE International Conference on Pattern Recognition (<strong>ICPR</strong>)</em>, 2012
              <p>This paper uses dynamic Delunay grpah clustering for summarizing videos.</p>
            </td>
          </tr> </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Website template from <a href="https://jonbarron.info/"> this great guy!</a>
                </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>
</html>
