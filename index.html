<!-- saved from url=(0032)http://www.cs.berkeley.edu/~rbg/ -->
<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>Rameswar Panda</title>
<style type="text/css" media="screen">
html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 15pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
}

ul {
  list-style: circle;
  padding-top: 0.5em;
}

img {
  border: none;
}

li {
  padding-bottom: 0.4em;
  margin-left: 1.4em;
}

strong, b {
	font-weight:bold;
}

em, i {
	font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.subsec {
  clear: both;
  margin-bottom: 0.1em;
  background: #fff;
  padding: 0.5em 0.5em 0.5em 0.5em;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 0.5em 0.5em 0.5em 0.5em;
}

div.backg {
  background-color: #ffffd0;
  padding: 10px;
}

div.paper div {
  padding-left: 200px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 170px;
}

div.dissert {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.dissert div {
  padding-left: 10px;
}

img.dissert {
  margin-bottom: 0.5em;
  float: left;
  width: 140px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  margin: 0em 0;
  padding: 0;
}

div.paper pre {
  font-size: 1em;
}

</style>

<script type="text/javascript" async="" src="./page_files/ga.js"></script><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-7953909-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-18061189-2', 'auto');
  ga('send', 'pageview');
</script>

<script type="text/javascript" src="./page_files/hidebib.js"></script>

<link href="./page_files/css" rel="stylesheet" type="text/css">
<style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.38) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style></head>

<body>

<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 275px;">
  <div style="margin: 0 auto; line-height: 120%;">
    <img title="R. Panda" style="float: right; padding-right: .1em;padding-left: .5em; height: 180px;" src="./page_files/myphoto.jpeg">
    <div style="padding-left: 1em; vertical-align: top; height: 250px;">
      <span style="font-size: 18pt; line-height: 130%;">Rameswar Panda</span><br><br>
    <span>I am a Research Scientist at <a href="https://mitibmwatsonailab.mit.edu/">MIT-IBM Watson AI Lab</a>, Cambridge, where
      I work on solving real world problems using computer vision and machine learning.
    <br><br>
    I received my Ph.D. from <a href="http://www.ucr.edu">UC Riverside</a> in 2018, under the supervision of <a href="http://vcg.engr.ucr.edu/amit">Prof. Amit K. Roy-Chowdhury</a>. 
    Previously, I obtained my M.S. from <a href="http://www.jaduniv.edu.in/">Jadavpur University</a> (India) in 2013 supervised by <a href="https://sites.google.com/site/anandachowdhury/">Prof. Ananda S. Chowdhury</a>. 
    <br><br>
    I was very fortunate to have interned at <a href="http://www.nec-labs.com/">NEC Labs America</a> (Cupertino, Summer 2018), <a href="https://research.adobe.com/">Adobe Research</a> (San Jose, Summer/Fall 2017) and <a href="http://www.usa.siemens.com/en/about_us/research/home.htm">Siemens Corporate Research</a> (Princeton, Summer 2016).
    <br><br>
	  <a href="mailto:rpanda@ibm.com">Email</a> / <a href="https://rpand002.github.io/Rameswar_Resume.pdf">Curriculum Vitae</a> / <a href="https://scholar.google.co.in/citations?user=_ySuu6gAAAAJ&hl=en">Google scholar</a> / <a href="https://www.linkedin.com/in/rameswar-panda-0067b2ab">Linkedin</a> </span>
    <br><br>
    <!--I will join <a href="http://www.research.ibm.com/labs/cambridge/">IBM Research, Cambridge</a> <a href="http://mitibmwatsonailab.mit.edu/">(MIT-IBM Watson AI Lab)</a> as a Research Scientist this December.-->
    </div>
  </div>
</div>

<div class="section">
<h2>Research</h2>
  <div class="paper">
My research interests mainly lie in the areas of computer vision, machine learning and multimedia computing. 
In particular, my current focus is on learning with limited supervision (transfer learning, few-shot learning) and dynamic computation for several computer vision problems.
During my Ph.D., I worked on video summarization, person re-identification in video surveillance, and multi-modal embedding.    
<p></p>
  </div>
</div>

<!-- I left this here just in case you bothered to look for it.
<div class="section">
  <h3>I'm on the faculty job market</h3><a href="papers/cv.pdf">cv</a> / <a href="app/research.pdf">research statement</a> / <a href="app/teaching.pdf">teaching statement</a>
  / <a href="http://scholar.google.com/citations?user=W8VIEZgAAAAJ&hl=en&oi=ao">google scholar</a>
</div>
-->

<div class="section">
  <h2>News</h2>
  <div class="subsec">

 <div class="subsec">
    <strong> 2020</strong>  <br><br>
      <strong><li></strong> Paper on Adversarial Knowledge Transfer from Unlabeled Data accepted at <a href="https://2020.acmmm.org/">ACM MM 2020</a>.<br>
      <strong><li></strong> Paper on Adaptive Frame Resolution for Efficient Action Recognition accepted at <a href="https://eccv2020.eu/">ECCV 2020</a>.<br>
      <strong><li></strong> Paper on Fairness of Classifiers Across Skin Tones in Dermatology accepted at <a href="https://www.miccai2020.org/en/">MICCAI 2020</a>.<br>
      <strong><li></strong> We are organizing the 2nd edition of our <a href="https://sites.google.com/view/multimodalvideo-v2/">Workshop on Multi-modal Video Analysis</a> at <a href="https://eccv2020.eu/">ECCV 2020</a>.<br>
      <strong><li></strong> Paper on Non-Adversarial Video Synthesis accepted at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.<br>
      <strong><li></strong> Paper on Hypothesis Transfer Learning for Person Re-ID accepted at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.<br>
      <strong><li></strong> We are organizing a <a href="https://sites.google.com/view/cvpr20-nas/">Workshop on Neural Architecture Search (NAS)</a> at <a href="http://cvpr2020.thecvf.com/">CVPR 2020</a>.<br>
   </div>

  <div class="subsec">
    <strong> 2019</strong>  <br><br>
      <strong><li></strong> Paper on Estimating Skin Tone accepted to NeurIPS Fair Machine Learning for Health Workshop.<br> 
      <strong><li></strong> Paper on Adaptation of Person Re-ID Models accepted to Pattern Recognition (PR).<br> 
      <strong><li></strong> We are organizing a <a href="https://sites.google.com/view/multimodalvideo/">Workshop on Multi-modal Video Analysis</a> at <a href="http://iccv2019.thecvf.com/">ICCV 2019</a>.<br>
     <strong><li></strong> We are organizing a tutorial on <a href="https://rpand002.github.io/cvpr19_sumt.html">Recent Advances in Visual Data Summarization</a> at <a href="http://cvpr2019.thecvf.com/">CVPR 2019</a>.<br>
     <strong><li></strong> Paper on Construction of Diverse Image Datasets accepted to IEEE TCSVT.<br>
   </div>

</div>
</div>

<div class="section">
<h2 id="papers"> Publications</h2>  
<br>
<h2 id="2020">2020</h2>

<div class="paper" id="Panda:PR19">

<div class="paper" id="Panda:PR19">
  <img class="paper" title="PR 2019" src="./page_files/PR2019.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/PR_2019.pdf"> Adaptation of Person Re-identification Models for On-boarding New Camera(s) </a><br>
    <strong>Rameswar Panda</strong>, Amran Bhuiyan, Vittorio Murino, Amit K. Roy-Chowdhury<br>
    Pattern Recognition (PR), 2019 <br>
    <span class="blurb"> This paper extends our CVPR 2017 paper providing a new source-target selective adaptation strategy and rigorous experiments on more datasets. </span> 
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="Panda:TCSVT19">
  <img class="paper" title="TCSVT 2019" src="./page_files/TCSVT2019.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/TCSVT_2019.pdf"> Construction of Diverse Image Datasets from Web Collections with Limited Labeling</a><br>
    Niluthpol C. Mithun, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
    IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2019 <br>
    <span class="blurb">This paper extends our MM 2016 paper where 
    we employ a joint visual-semantic space to simultaneously utilize both images and associated textual information from the web for dataset construction.</span>
  </div>
  <div class="spanner"></div>
</div>
</div>

<div class="paper" id="Panda:TMM17">
  <img class="paper" title="TMM 2017" src="./page_files/TMM2017.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/TMM_2017.pdf"> Multi-View Surveillance Video Summarization via Joint Embedding and Sparse Optimization</a><br>
    <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
    IEEE Transactions on Multimedia (TMM), 2017 <br>
    <span class="blurb">This paper extends our ICPR 2016 paper providing new theoretical insights with a joint optimization and experimenting on spatio-temporal features and datasets.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="Panda:TIP17">
  <img class="paper" title="TIP 2017" src="./page_files/TIP2017.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/TIP_2017.pdf"> Diversity-aware Multi-Video Summarization</a><br>
    <strong>Rameswar Panda</strong>, Niluthpol C. Mithun, Amit K. Roy-Chowdhury<br>
    IEEE Transactions on Image Processing (TIP), 2017 <br>
    <span class="blurb">Extension of our ICASSP 2017 paper. We propose a new generalized sparse optimization framework for summarizing multiple videos generated from a video search or from a multi-view camera network.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="Panda:TCYB16">
  <img class="paper" title="TCYB 2016"" src="./page_files/TCYB2017.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/TCYB.pdf">Nystrom approximated temporally constrained multi-similarity spectral clustering approach for movie scene detection</a><br> 
    <strong>Rameswar Panda</strong>, Sanjay K. Kuanar, Ananda S. Chowdhury<br>
     IEEE Transactions on Cybernetics (TCYB), 2017<br>

     <span class="blurb">We present a fast solution for movie scene detection using Nystrom approximated multi-similarity spectral clustering with a temporal integrity constraint.</span>
  </div>
  <div class="spanner"></div>
</div>


  <div class="paper" id="Panda:CVIU16">
  <img class="paper" title="CVIU 2016" src="./page_files/CVIU2016.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/CVIU_2016.pdf">Continuous Adaptation of Multi-Camera Person Identification Models through Sparse Non-redundant Representative Selection</a><br>
    Abir Das, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
    Computer Vision and Image Understanding (CVIU), 2016<br>

    <span class="blurb">We addressed the problem of online learning of identification systems where unlabeled data comes in small minibatches, with human in the loop.</span>

  </div>
  <div class="spanner"></div>
</div>

    

<div class="paper" id="Panda:JVCIR13">
  <img class="paper" title="JVCIR 2013" src="./page_files/JVCI20131.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/JVCI.pdf"> Video Key frame Extraction through Dynamic Delaunay Clustering with a Structural Constraint</a><br>
    Sanjay K. Kuanar, <strong>Rameswar Panda</strong>, Ananda S. Chowdhury<br>
    Journal of Visual Communication and Image Representation (JVCIR), 2013<br>
    <span class="blurb">This paper extends our ICPR 2012 paper providing new theoretical insights and experimenting on more features and datasets.</span>
  </div>
  <div class="spanner"></div>
</div>
</div>
</div>


<div class="section">
<h2 id="confpapers">Selected Conference Publications</h2> (see my <a href="https://scholar.google.co.in/citations?user=_ySuu6gAAAAJ&hl=en">Google Scholar</a> for the full list of papers)

<div class="paper" id="Panda:CVPR2020_non">
  <img class="paper" title="CVPR 2020_non" src="./page_files/CVPR2020_non.jpg">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/CVPR_2020_non.pdf">Non-Adversarial Video Synthesis with Learned Priors</a><br>
    Abhishek Aich, Akash Gupta, <strong>Rameswar Panda</strong>, Rakib Hyder, Salman Asif, Amit Roy-Chowdhury <br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020<br>

    <span class="blurb"> We introduce a novel non-adversarial framework for generating videos from latent noise vectors 
      without any reference input frame.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="Panda:CVPR2020_ReID">
  <img class="paper" title="CVPR 2020_ReID" src="./page_files/CVPR2020_reid.jpg">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/CVPR_2020_ReID.pdf">Camera On-boarding for Person Re-identification using Hypothesis Transfer Learning</a><br>
    Sk Miraj Ahmed, Aske R. lejbolle, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury <br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020<br>

    <span class="blurb"> We propse an approach to swiftly on-board new camera(s) in an existing person re-id network without having access to the source camera data
      and relying upon only a small amount of labeled data after adding the new camera(s).</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="Panda:ECCV2018_Emo">
  <img class="paper" title="ECCV 2018_Emo" src="./page_files/ECCV2018.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ECCV_2018.pdf">Contemplating Visual Emotions: Understanding and Overcoming Dataset Bias</a><br>
    <strong>Rameswar Panda</strong>, Jianming Zhang, Haoxiang Li, Joon-Young Lee, Xin Lu, Amit K. Roy-Chowdhury<br>
    European Conference on Computer Vision (ECCV), 2018<br>
    <a href="https://rpand002.github.io/emotion.html"> [Project Page] </a> 
    <a href="https://rpand002.github.io/Papers/ECCV_2018_Supp.pdf"> [Supplementary Material] </a> 


    <span class="blurb"> We investigate different dataset biases and propose a curriculum guided webly supervised approch
    for learning a generalizable emotion recognition model.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="Panda:MM18">
  <img class="paper" title="MM 2018" src="./page_files/MM2018.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/MM_2018.pdf">Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval</a><br>
    Niluthpol C. Mithun, <strong>Rameswar Panda</strong>, Evangelos E. Papalexakis, Amit K. Roy-Chowdhury<br>
    ACM International Conference on Multimedia (MM), 2018<br>

    <span class="blurb">This work exploits large scale web data for learning an effective multi-modal
embedding without requiring large amount of human-crafted training data.</span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="Panda:CVPR2018_Summ">
  <img class="paper" title="CVPR 2018_Summ" src="./page_files/CVPR2018.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/CVPR_2018_Shuyue.pdf">FFNet: Video Fast-Forwarding via Reinforcement Learning</a><br>
    Shuyue Lan, <strong>Rameswar Panda</strong>, Qi Zhu, Amit K. Roy-Chowdhury<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018<br>

    <span class="blurb"> We introduce an online framework for fast-forwarding a video 
  without processing or even obtaining the entire video.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="Panda:ICCV2017_Summ">
  <img class="paper" title="ICCV 2017_Summ" src="./page_files/ICCV2017.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ICCV_2017.pdf">Weakly Supervised Summarization of Web Videos</a><br>
    <strong>Rameswar Panda</strong>, Abir Das, Ziyan Wu, Jan Ernst, Amit K. Roy-Chowdhury<br>
    International Conference on Computer Vision (ICCV), 2017<br>

    <span class="blurb"> We
introduce a weakly supervised approach that requires only
video-level annotation for summarizing web videos. </span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="Panda:CVPR2017_Reid">
  <img class="paper" title="CVPR 2017_Reid" src="./page_files/CVPR2017Reid1.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/CVPR_2017_Reid.pdf">Unsupervised Adaptive Re-identification in Open World Dynamic Camera Networks</a><br>
    <strong>Rameswar Panda</strong>, Amran Bhuiyan, Vittorio Murino, Amit K. Roy-Chowdhury<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017<br>

    <span class="blurb"> We propose an unsupervised adaptation scheme for for re-identification models in a dynamic camera network where a new camera
may be temporarily inserted into an existing system
to get additional information. </span>
  </div>
  <div class="spanner"></div>
</div>

<div class="paper" id="Panda:CVPR2017_Summ">
  <img class="paper" title="CVPR 2017_Summ" src="./page_files/CVPR2017Summ.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/CVPR_2017_Summ.pdf">Collaborative Summarization of Topic-Related Videos</a><br>
    <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017<br>

    <span class="blurb"> This paper presents a collaborative video summarization approach that exploits visual context from a set of topic-related videos to extract an informative summary of a given video.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="Panda:ICASSP2017">
  <img class="paper" title="ICASSP 2017" src="./page_files/ICASSP2017.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ICASSP_2017.pdf">Sparse Modeling for Topic-oriented Video Summarization</a><br>
    <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
    IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2017<br>

    <span class="blurb"> This paper presents a diversity-aware sparse optimization framework for summarizing topi-related videos generated from a video search.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="Panda:ICPR16">
  <img class="paper" title="ICPR 2016" src="./page_files/ICPR2016.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ICPR_2016.pdf">Video Summarization in a Multi-View Camera Network</a><br>
    <strong>Rameswar Panda</strong>, Abir Das, Amit K. Roy-Chowdhury<br>
    IEEE International Conference on Pattern Recognition (ICPR), 2016<br>

    <span class="blurb">This paper presents a framework for summarizing multi-view videos by exploiting both intra- and inter-view content correlations in a joint embedding space.</span>
  </div>
  <div class="spanner"></div>
</div>
  

<div class="paper" id="Panda:ICIP16">
  <img class="paper" title="ICIP 2016" src="./page_files/ICIP2016.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ICIP_2016.pdf">Embedded Sparse Coding for Summarizing Multi-View Videos</a><br>
    <strong>Rameswar Panda</strong>, Abir Das, Amit K. Roy-Chowdhury<br>
    IEEE International Conference on Image Processing (ICIP), 2016<br>

    <span class="blurb">This paper presents a stochastic multi-view frame embedding based on KL diveregence to preserve correlations in multi-view learning.</span>
  </div>
  <div class="spanner"></div>
</div>



<div class="paper" id="Panda:MM16">
  <img class="paper" title="MM 2016" src="./page_files/MM2016.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/MM_2016.pdf">Generating Diverse Image Datasets with Limited Labeling</a><br>
    Niluthpol C. Mithun, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
    ACM International Conference on Multimedia (MM), 2016<br>

    <span class="blurb">This paper presents a semi-supervised sparse coding framework to collect a diverse set of images with minimal human effort.</span>
  </div>
  <div class="spanner"></div>
</div>


<div class="paper" id="Panda:ICIP15">
  <img class="paper" title="ICIP 2015" src="./page_files/ICIP2015.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ICIP_2015.pdf">Active Image Pair Selection for Continuous Person Re-identification</a><br>
    Abir Das, <strong>Rameswar Panda</strong>, Amit K. Roy-Chowdhury<br>
    IEEE International Conference on Image Processing (ICIP), 2015<br>

    <span class="blurb">We present a continuous learning re-id system with a human in the loop.</span>
  </div>
  <div class="spanner"></div>
</div>



<div class="paper" id="Panda:ICPR14">
  <img class="paper" title="ICPR 2014" src="./page_files/ICPR2014.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ICPR_2014.pdf">Scalable Video Summarization using Skeleton Graph and Random Walk</a><br>
    <strong>Rameswar Panda</strong>, Sanjay K. Kuanar, Ananda S. Chowdhury<br>
    IEEE International Conference on Pattern Recognition (ICPR), 2014<br>

    <span class="blurb">This paper presents a video summarization framework which is scalable during both the analysis and the generation stages of video summarization.</span>
  </div>
  <div class="spanner"></div>
</div>



<div class="paper" id="Panda:ICPR12">
  <img class="paper" title="ICPR 2012" src="./page_files/ICPR2012.png">
  <div>
    <a class="paper" href="https://rpand002.github.io/Papers/ICPR_2012.pdf">Video Storyboard Design using Delaunay Graphs</a><br>
    Ananda S. Chowdhury, Sanjay K. Kuanar, <strong>Rameswar Panda</strong>, Moloy N. Das<br>
    IEEE International Conference on Pattern Recognition (ICPR), 2012<br>

    <span class="blurb">This paper uses dynamic Delunay grpah clustering for summarizing videos.</span>
  </div>
  <div class="spanner"></div>
</div>



</div>

<div style="clear:both;">
  <p align="right"><font size="2"><a href="http://jonbarron.info/">I like this website</a></font></p><br>
</div>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>


</body></html>
