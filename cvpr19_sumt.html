<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
<title>CVPR 2019 Summarization Tutorial</title>
<style type="text/css" media="screen">
html, body, div, span, applet, object, iframe, h1, h2, h3, h4, h5, h6, p, blockquote, pre, a, abbr, acronym, address, big, cite, code, del, dfn, em, font, img, ins, kbd, q, s, samp, small, strike, strong, sub, tt, var, dl, dt, dd, ol, ul, li, fieldset, form, label, legend, table, caption, tbody, tfoot, thead, tr, th, td {
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}

a {
  color: #1772d0;
  text-decoration:none;
}

a:focus, a:hover {
  color: #f09228;
  text-decoration:none;
}

a.paper {
  font-weight: bold;
  font-size: 12pt;
}

b.paper {
  font-weight: bold;
  font-size: 12pt;
}

* {
  margin: 0pt;
  padding: 0pt;
}

body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 800px;
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #eee;
}

h2 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 18pt;
  font-weight: 700;
}

h3 {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 16px;
  font-weight: 700;
}

strong {
  font-family: Lato, Verdana, Helvetica, sans-serif;
  font-size: 13px;
}

ul {
  list-style: circle;
}

img {
  border: none;
}

li {
  padding-bottom: 0.5em;
  margin-left: 1.4em;
}

strong, b {
  font-weight:bold;
}

em, i {
  font-style:italic;
}

div.section {
  clear: both;
  margin-bottom: 1.5em;
  background: #eee;
}

div.spanner {
  clear: both;
}

div.paper {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.paper div {
  padding-left: 200px;
}

img.paper {
  margin-bottom: 0.5em;
  float: left;
  width: 170px;
}

div.dissert {
  clear: both;
  margin-top: 0.5em;
  margin-bottom: 1em;
  border: 1px solid #ddd;
  background: #fff;
  padding: 1em 1em 1em 1em;
}

div.dissert div {
  padding-left: 150px;
}

img.dissert {
  margin-bottom: 0.5em;
  float: left;
  width: 140px;
}

span.blurb {
  font-style:italic;
  display:block;
  margin-top:0.75em;
  margin-bottom:0.5em;
}

pre, code {
  font-family: 'Lucida Console', 'Andale Mono', 'Courier', monospaced;
  margin: 1em 0;
  padding: 0;
}

div.paper pre {
  font-size: 0.9em;
}

</style>

<script type="text/javascript" async="" src="./page_files/ga.js"></script><script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-7953909-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>

<script type="text/javascript" src="./page_files/hidebib.js"></script>

<link href="./page_files/css" rel="stylesheet" type="text/css">
<!--<link href='http://fonts.googleapis.com/css?family=Open+Sans+Condensed:300' rel='stylesheet' type='text/css'>-->
<!--<link href='http://fonts.googleapis.com/css?family=Open+Sans' rel='stylesheet' type='text/css'>-->
<!--<link href='http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz' rel='stylesheet' type='text/css'>-->
<style id="style-1-cropbar-clipper">/* Copyright 2014 Evernote Corporation. All rights reserved. */
.en-markup-crop-options {
    top: 18px !important;
    left: 50% !important;
    margin-left: -100px !important;
    width: 200px !important;
    border: 2px rgba(255,255,255,.38) solid !important;
    border-radius: 4px !important;
}

.en-markup-crop-options div div:first-of-type {
    margin-left: 0px !important;
}
</style></head>

<body>

<div style="margin-bottom: 1em; border: 1px solid #ddd; background-color: #fff; padding: 1em; height: 150px;">
    <div style="padding-left: 1em; vertical-align: top; height: 250px;">
      <span style="font-size: 18pt; line-height: 130%;">Recent Advances in Visual Data Summarization</span><br><br>
    <span>  CVPR 2019 Tutorial<br><br>
    Location: Room 203C
    <br><br>
    Sunday, June 16, 1:30 pm - 5:30 pm   
    <br><br>
    </div>
  </div>
</div>


<div class="section">
<h2> Organizers </h2>
  <div class="paper">
  <strong><li></strong> <a href="https://rpand002.github.io/">Rameswar Panda</a>: Research Staff Member, IBM Research AI, MIT-IBM Watson AI Lab</a>.<br>
  <strong><li></strong> <a href="http://www.ccs.neu.edu/home/eelhami/">Ehsan Elhamifar</a>: Assistant Professor, Northeastern University</a>.<br>
  <strong><li></strong> <a href="https://gyglim.github.io/me/index.html">Michael Gygli</a>: Research Scientist, Google AI, Zurich</a>.<br>
  <strong><li></strong> <a href="http://boqinggong.info/">Boqing Gong</a>: Research Scientist, Google AI, Seattle</a>.<br>
</div>
</div>



<div class="section">
<h2>Tutorial Description</h2>
  <div class="paper">
Visual data summarization has many applications 
ranging from computer vision (video summarization, video
captioning, active visual learning, object detection, image/video
segmentation, etc) to data mining (recommender systems, webdata analysis, etc). 
As a consequence, new important research topics
and problems are recently appearing, (i) online and distributed
summarization, (ii) weakly supervised summarization, (iii)
summarization in sequential data, as well as (iv) summarization in
networks of cameras, in particular, for surveillance tasks. The
objective of this tutorial is to present the audience with a unifying
perspective of the visual data summarization problem from both
theoretical and application standpoint, as well as to discuss,
motivate and encourage future research that will spur disruptive
progress in the the emerging field of summarization. 
</div>
</div>

<div class="section">
<h2>Schedule</h2>
  <div class="paper">
  <strong><li></strong> 1:30 pm - 2:00 pm: Rameswar Panda: Overview of Visual Data Summarization</a>.<br>
  <strong><li></strong> 2:00 pm - 3:00 pm: Ehsan Elhamifar: Overview of Visual Data Summarization</a>.<br>
  <strong><li></strong> 3:00 pm - 3:30 pm: Break</a>.<br>
  <strong><li></strong> 3:30 pm - 4:30 pm: Michael Gygli: Overview of Visual Data Summarization</a>.<br>
  <strong><li></strong> 4:30 pm - 5:00 pm: Boqing Gong: Overview of Visual Data Summarization</a>.<br>
</div>
</div>

<div class="section">
<h2>Target Audience</h2>
  <div class="paper">
The intended audience are academicians, graduate students and industrial
researchers who are interested in the state-of-the-art machine learning techniques for information
extraction and summarization in large high-dimensional datasets that are considered to be mixed,
multi-modal, inhomogeneous, heterogeneous, or hybrid. Audience with mathematical and theoret-
ical inclination will enjoy the course as much as the audience with practical tendency.
</div>
</div>

<div class="section">
<h2>Speaker Bios</h2>
  <div class="paper">
  <strong><li></strong> <a href="https://rpand002.github.io/">Rameswar Panda</a> is currently a Research Staff Member at IBM 
  Research AI, MIT-IBM Watson AI Lab, Cambridge, USA. Prior to joining IBM, he obtained his Ph.D in Electrical and Computer Engineering from
   University of California, Riverside in 2018. His primary research interests span thevareas of computer vision, machine learning and multimedia. 
   In particular, his current focus is on developing semi, weakly, unsupervised algorithms for solving different vision problems. 
  His work has been published intop-tier conferences such as CVPR, ICCV, ECCV, MM as well as high impact journals such as TIP and TMM.</a>.<br>
</div>
</div>

</body></html>
